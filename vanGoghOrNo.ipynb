{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImagePrep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bezzeNobKA-5"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEuF38HWLkoI",
        "outputId": "7f8dbd69-42bc-4a54-d7a4-33e6f2afc8ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-C1qTWnGQg9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from google.colab import files\n",
        "import random\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8-s0BrCf8oc"
      },
      "source": [
        "trainingPath = \"/content/gdrive/MyDrive/Data_Analysis_Class/Project 4/Images/\"\n",
        "pictureList = []\n",
        "className = []\n",
        "image_path= os.listdir(trainingPath)\n",
        "for i in image_path:\n",
        "  image = mpimg.imread(trainingPath + i)\n",
        "  image = resize(image, (299, 299), anti_aliasing=True)\n",
        "  pictureList.append(image)\n",
        "  if \"gogh\" in i:\n",
        "    className.append(1)\n",
        "  else:\n",
        "    className.append(0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLjccd8iRy3"
      },
      "source": [
        "className = np.array(className)\n",
        "pictureList = np.array([i / 255 for i in pictureList])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLIKycE0OK_e"
      },
      "source": [
        "# imageWidth = 255\n",
        "# imageHeight = 255\n",
        "# img_folder=r'/content/gdrive/MyDrive/Data_Analysis_Class/Project 4/Images_training'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIQHX4Q5YmoC"
      },
      "source": [
        "pretrained_base = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    include_top=True, weights='imagenet', input_tensor=None,\n",
        "    input_shape=(299, 299, 3), pooling=None, classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFX7vs04mDkn"
      },
      "source": [
        "pretrained_base.trainable = False"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAWKq8komLcU"
      },
      "source": [
        "newModel = keras.Sequential([\n",
        "    preprocessing.RandomFlip('horizontal'),\n",
        "    preprocessing.RandomContrast(0.5),\n",
        "    pretrained_base,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=8, activation='relu'),\n",
        "    layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7uUmM9mj8-"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
        "newModel.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EHNj7AemmcM",
        "outputId": "cf6cccc2-f867-41aa-8ef1-65b5e9c35bf8"
      },
      "source": [
        "history = newModel.fit(pictureList, className, epochs=30)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 14s 3s/step - loss: 0.6926 - binary_accuracy: 0.7400\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6921 - binary_accuracy: 0.7400\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6918 - binary_accuracy: 0.7400\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6913 - binary_accuracy: 0.7400\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6907 - binary_accuracy: 0.7400\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6901 - binary_accuracy: 0.7400\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6894 - binary_accuracy: 0.7400\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6887 - binary_accuracy: 0.7400\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6880 - binary_accuracy: 0.7400\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6873 - binary_accuracy: 0.7400\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6866 - binary_accuracy: 0.7400\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6858 - binary_accuracy: 0.7400\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6851 - binary_accuracy: 0.7400\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6843 - binary_accuracy: 0.7400\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6835 - binary_accuracy: 0.7400\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6827 - binary_accuracy: 0.7400\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6820 - binary_accuracy: 0.7400\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6812 - binary_accuracy: 0.7400\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6804 - binary_accuracy: 0.7400\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6796 - binary_accuracy: 0.7400\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6788 - binary_accuracy: 0.7400\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6781 - binary_accuracy: 0.7400\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6773 - binary_accuracy: 0.7400\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6765 - binary_accuracy: 0.7400\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6757 - binary_accuracy: 0.7400\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6749 - binary_accuracy: 0.7400\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6742 - binary_accuracy: 0.7400\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6734 - binary_accuracy: 0.7400\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6727 - binary_accuracy: 0.7400\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.6719 - binary_accuracy: 0.7400\n"
          ]
        }
      ]
    }
  ]
}